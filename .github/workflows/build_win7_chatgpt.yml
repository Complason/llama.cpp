name: win7-llama-server

on:
  workflow_dispatch:
  push:
    paths:
      - ".github/workflows/win7-llama-server.yml"
      - "CMakeLists.txt"
      - "ggml/**"
      - "examples/**"
      - "tools/server/**"

jobs:
  # 方案 A：MSVC 静态运行时 + 显式 Win7 子系统版本
  msvc-static:
    runs-on: windows-2022
    steps:
      - uses: actions/checkout@v4

      - name: Configure (MSVC, Win7-compatible, static runtime)
        shell: bash
        run: |
          cmake -S . -B build-msvc -G "Visual Studio 17 2022" -A x64 \
            -DLLAMA_BUILD_SERVER=ON \
            -DLLAMA_CURL=OFF \
            -DGGML_CUDA=OFF -DGGML_VULKAN=OFF \
            -DCMAKE_MSVC_RUNTIME_LIBRARY=MultiThreaded \
            -DCMAKE_C_FLAGS="/D_WIN32_WINNT=0x0601 /DWINVER=0x0601" \
            -DCMAKE_CXX_FLAGS="/D_WIN32_WINNT=0x0601 /DWINVER=0x0601" \
            -DCMAKE_EXE_LINKER_FLAGS="/SUBSYSTEM:CONSOLE,6.01"

      - name: Build (Release, target llama-server)
        run: cmake --build build-msvc --config Release --target llama-server --parallel

      - name: Upload artifact (MSVC)
        uses: actions/upload-artifact@v4
        with:
          name: llama-server-msvc-win7
          path: |
            build-msvc/bin/Release/llama-server.exe

  # 方案 B：MinGW 完全静态（msvcrt 工具链），Win7 兜底版
  mingw-static:
    runs-on: windows-2022
    steps:
      - uses: actions/checkout@v4

      - name: Setup MSYS2 (MINGW64 toolchain)
        uses: msys2/setup-msys2@v2
        with:
          msystem: MINGW64
          update: true
          install: >-
            mingw-w64-x86_64-gcc
            mingw-w64-x86_64-cmake
            make

      - name: Configure & Build (MinGW static, Win7)
        shell: msys2 {0}
        run: |
          export CFLAGS="-O3 -D_WIN32_WINNT=0x0601 -DWINVER=0x0601 -static -static-libgcc -static-libstdc++"
          export CXXFLAGS="$CFLAGS"
          export LDFLAGS="-static -static-libgcc -static-libstdc++ -Wl,--major-subsystem-version,6 -Wl,--minor-subsystem-version,1"
          cmake -S . -B build-mingw -G "Unix Makefiles" \
            -DCMAKE_BUILD_TYPE=Release \
            -DBUILD_SHARED_LIBS=OFF \
            -DLLAMA_BUILD_SERVER=ON \
            -DLLAMA_CURL=OFF \
            -DGGML_CUDA=OFF -DGGML_VULKAN=OFF
          cmake --build build-mingw --parallel
          # 可选：减小体积
          which strip && strip build-mingw/bin/llama-server.exe || true

      - name: Upload artifact (MinGW)
        uses: actions/upload-artifact@v4
        with:
          name: llama-server-mingw-win7-static
          path: build-mingw/bin/llama-server.exe
